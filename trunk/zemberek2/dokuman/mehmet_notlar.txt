TSpell Notlar

Haziran 2004

1. Kok seciciler ve Performans
Ne yazık ki hash secici istediğim performansı sağlayamadı, bir iki temizlik ve
numara ekleyip yaklaşık 280.000 kök/s de sabitledim, aslında yapılabilcek bir kaç şey
daha var. 
- String sınıfının toCharArray() metodu oldukça yavaş, eğer kök seçiciye doğrudan bir 
karakter dizisi gönderirsek %15-20 hızlanabilir. 
- Karsilastirma icin bir tur ozel hash degeri kullanilabilir, bu da %5-10 arasi bir getiri 
yapabilir.
Ancak basit yapılı MapSecici zaten yaklasik 240.000 lik bir peformansa sahip
o yuzden eziyete değer mi bilinmez, en iyisi şimdilik bu çalışmayı ikinci plana atmak.
Tabi MapSecicinin her zaman dogru adaylari getirmedigi bir gercek fakat gene de elde
edecegimiz %20-25 lik ekstar performans icin simdilik kasmaya gerek yok.; 

2.Kelimeler
(TurkceHarf <- HarfDizisi <- Kelime) Su anda kullanmakta olduğumuz bu yapının yerine
(char[] <- Kelime) şeklinde bir basitleşmeye gitmenin getirisi ve götürüsü ne olur acaba?
Getiriler: Daha basit bir yapı ve kolay debug, daha küçük bellek ihtiyacı
Götürüler: Daha az modüler ve nesneye yönelimli yapı (ancak iyileştirilebilir)
Belirsiz : Performans, nesnelerden doğrudan çağrı ile yapılacak işler için bazı boolean
 kelime haritaları kullanılması gerekecek. Ancak bunlar nesne oluşturma ve çağırma bedellerinden
 küçükse daha iyi performans gösterebilir. denenmeli.

Soru: Kelime sınıfını "Java String" sınıfının Türkçe için özelleşmiş bir versiyonu gibi kullanabilir miyiz?

.... 

Nisan - Mayıs 2004
Refactoring ihtiyacı:
Bir kelime enflasyonumuz var ve çözülmesi gerekiyor.
Elimizdeki kelime, kök, sozluk kelimesi vs ye bir bakalım:

TurkceHarf : Tek bir turkce harfi ifade ediyor, harfin kendisi, sirasi, sert, yumusakligi vs gibi bilgileri tasiyor. 
HarfDizisi : TurkceHarf dizisi tasiyan bir container. karmasik karsilastirma, buyuyebilme gibi ozellikleri tasiyor
Kok    : Istitsnalari ve kelimenin yalin halini tutan sinif. istisnalarin ve degisime ugramis hallerin olusmasinda kullaniliyor.
Kelime : Icinde bir harf dizisi(HarfDizisi turunde) ve Kok tasiyan ana Kelime sinifi
SozlukKelime : [Miadi dolmus]Benim eski sozlugu okumak icin yapmis oldugum istisnai durumlari ve kelime tipini tasiyan sinif
SozlukKelimesi : SozlukKelime'nin yerini alan ve Kok karsilastirmasi isleminde kullanilan icinde istisnalari tasiyan Kok'u
                 ve kelimenin kendisini tasiyan sinif.
KelimeTuru : [Tartismali]aslinda bir enum. "bence bu sinif yokolabilir" bir kelimenin Turunu ifade etmek icin bu tur bir
sinifa ihtiyacimiz yok, icinde sadece debug icin bir String tasiyor, onun yerine Kelime veya SozlukKelimesi siniflarindan
birinin icine sabit int'ler koymak cok daha sade ve dogru.


- FilteringStream
MetinAraclari sinifinda hep benzeri isler yapiliyor, ozellikle injecterror ve ASCIIfyTurkish 
gibi minik araclar icin bir tür FilePipe yapmak iyi olacak
soyle ki, bu pipe input olarak String, FileName veya Stream alabilecek,
output olarak ta gene ayni turden bir cikti verecek. tabi bir suru constructor gerekli.

Bir de StreamFilter arayuzu yapip FilteringStream'in okudugu karakterleri dizi olarak veya
kelime olarak belirtilen StreamFileter'e verebilir. StreamFilter okunan veriyi isler ve 
geri verir. Sonuc olarak her seferinde dosya ac, kapa , oku yapmak yerine bir FilteringStream
nesnesi olusturup uygun StreamFilter nesnesini - veya nesnelerini - register etmek yeterli 
olabilir. 

Bir ara yapacagim. Refactoring iyidir vesselam.


- 13 Mart 2004
Karakter kodlaması.. bela mı bela. işin doğrusu bu konuyu eskiden beri sevmezdim, konu Türkçe
olunca gene hortladı tabi anında. 

- 10 Mart 2004
İstatistikler.. Yaptığımız işlemler sırasında çeşitli istatistikleri de tutabiliriz, biraz
düşünelim, en basitinden en tuhafına kadar. Verilen bir metin için:
Yapısal olarak:

 - Harf sayısı
 - Hece sayısı
 - Kelime sayısı
 - Cümle sayısı
 - Hepsinin oranları (En çok kullanılan harf, hece, kelime vs.)
 - Ortalama kelime uzunluğu
 - Ortalama Cümle uzunluğu
 - En uzun kelime
 - En uzun cümle
 
 Imla denetimi ve Gramer yönünden :
 
 - isim, Sıfat, Fiil vs sayısı  ve oranları
 - En sık kullandığı kelime, ek, hece
 - Kelime kökenlerine göre sayılar ve oranları (Arapça, Fransoıca vs.)
 - Denetim doğruluk oranı
 - Kelimelerin anlamsal türlerinin oranı (Bilimsel, genel, hukuki vs)
 - Olumsuz cümle oranı ?
 - Soru cümlesi sayısı ?
 
 Gizli istatistikler
 - Genel Türkçe metinlerden sapma miktarı (genel Ek sıralamasından sapma oranı - cache-miss, 
   Kök adayı vuru oranı vs. Bu istatistik bizim büyük miktarda veriyi taramamızdan sonra 
   toplanabilir.) 
  
  Tüm bu istatistikler herhangi bir metin için bir rapor şeklinde sunulabilse iyi olurdu sanırım.
 
Sözlük işini ben aldım. Elimizdeki kısmen dönüştürülmüş sözlüğü bizim istediğimiz formata
getireceğim, diğer taraftan da basit bir xml sözlük hazırlayacağım, hayırlısı.

- 6 Mart 2004
Kelime sayısı ile ilgili tahminim hatalı olabilir, Osmanlıca kelimeleri ekleyince sayı ikiyüzbini 
bulabiliyor sanırım.
Biraz sözlük üzerinde düşünelim, Ahmet'in bu konudaki bilgisi çok daha geniş.. Kabaca sayacak olursak;
 Kelimenin biçimsel özellikleri
  - Türü (isim, sıfat, fiil, zarf, zamir, edat)
  - Orijini (Türkçe, Arapça, Farsça, Fransızca ...)
  - Sonu sert sessizle mi bitiyor?
  - Dğer özel durumlar (bunlar için Ahmet özel karakterler kullanıyordu)
 Anlamsal özellikler? 
  - Sanırım bu konuda şimdilik tam bir muamma..

Aslında sözlük girişi için basit bir php veya java arayüzü yapılıp bilgiler bir Musql veritabanına
girilirse daha iyi olacakmış gibi görünüyor. binary ve xml sözlükler bu veritabanı sorgulanarak
oluşturulabilir.


- 5 Mart 2004

İMLA DENETİMİ
imla denetimi algoritması kabaca şu adımlardan oluşuyor

1. Sözlüğün okunması : Sadece en başta yapılıyor
   - Sözlük genişleyebilir yapıda, muhtemelen XML formatında olacak, ayrıca bu sözlüğü binary
     formata dönüştüren bir kütüphane fonksiyonuna da ihtiyacımız olacak, ancak taban daima okunaklı
     ve esnek olan XML sözlük olmalı. Bu konuda yapılmış çalışmalar taban alınabilir. 
   - Türkçede yüzbin civarında muhtemel kelime var, ortalama olarak xml versiyonunun 4-5 MB, binary 
     versiyonunun da 1 MB civarında olması muhtemel. Taşınabilirliği arttırmak için sıkıştırma yolu
     da denenebilir.

2. Denetim yapılacak kelime için ön inceleme - işlem yapılması
   - Çok mu kısa? 'o' hariç.
   - Çok mu uzun? <40 En uzun kelimemiz : Çekoslovakyalılaştırabileceklerimizden ?
   - Geçersiz harf taşıyor mu? <-- Azericede Q ve x var, o yüzden diyalektler için farklı olabilir. 
   - Noktalama işsretlerinden arındırılmalıdır
   - Tamamen küçük harfe dönüştürülmelidir.

3. Kök adaylarının belirlenmesi. Bu, hassas bir konu. 
   - Kitabım kelimesinin kökü 'kitap' tır ancak içinde kitap kelimesini barındırmaz. 
     Dolayısıyla kök analizinde sert sessiz ile biten kelimelerin yumuşak hallerinin de
     göz önüne alınması gerekiyor, bu durumda yumuşama şartı olan sert sessizden sonra 
     sesli harf gelme kuralı da dikkate alınabilir.
   - Performans: Çoğu kelime için tek bir kök adayı bulunacaktır, ancak bazı kelimelerin
     çok miktarda adayı olabilir.  örneğin "Elmaslarının" kelimesinin Üç adet aday kök'ü vardır
     "El","Elma" ve "Elmas". kök arama işleminin optimum olması kelime başına yapılan iş miktarını 
     da azaltacaktır.
   - Bu noktada, sırf kök adaylarının hızla belirlenebilmesi için bellekteki sözlüğün yanında
     daha hafif bir kök aday veri yapısının da bulundurulması anlamlı olabilir. Bu, belli bir
     bellek yükü de getirecektir, performans getirisi incelenmeli.

4. Kök yapıları: 
   - Türkçe'de kök kelimeler, kelimenin türüne göre farklı ekleri alabilir ve ekler birbirine
     bağlanırken belli kurallar vardır, bir eke sadce belli bazı ekler birleştirilebilir.
     Ahmet eski programda bu iş için bir ek matrisi hazırlamıştı, bu matrisi kullanmak gene 
     anlamlı olabilir.
   
5. Adaylar üzerinde kelime üzerinden gidilerek muhtemel ekler sentezlenir
   - Ahmet'in örneği üzernden girdersek, "Elmaslarının" kelimesi için önce "El" kelimesi bulunur
     (Bu noktada enteresan bir soru, Ahmet örneğinde El için önce çoğul ekinin deneneceğini ve Eller ile 
     uyuşmayacağından olmayacağını yazmış.  ancak ler - lar ekini denemenin bile anlamı yok, çünkü El'den
     sonra gelen harf zaten 'm', isim  köküne 'm' ile başlayan ek gelemeyeceğinden El, daha işin başında
     elenebilirdi. Belki de bu tür numaraları şimdilik programa dahil etmemekte fayda var.)
   - Sentez sonucunda elde edilen kelime giriş kelimesine eşit olduğu zaman kelime denetlemesi 
     başarı ile tamamlanır, eğer aday kök kalmamışsa denetleme başarısız demektir.  
   - Burada Perormans incelemesi yapılabilir, ayrıca adaptif algoritmalar kullanarak kök cinslerine
     göre , hatta her kök için gelmesi en muhtemel 2-3 ek'in indexi de sözlükle beraber tutulabilir,
     bu puanlandırmanın doğru olabilmesi için ilginç şey denenebilir
       - Programa milyonlarca kelime verilerek istatistiki bilgiler değerlendirilir
       - Metnin yapısına göre farklı ek seçim puanlandırılmaları yapabilir (jenerik, hukuki, bilimsel vs.)
     Performans çalışmasının bir diğer ayağı da karşılaştırma işlemlerindeki mini numaralar olabilir,
     hash değerlerinin karşılaştırılması vs gibi. 
     

6. İstisnai durumlar

KELİME TAVSİYESİ        
Bozuk kelimeler için uygun tavsiyelerde bulunmak oldukça farklı bir yol izlemeyi gerektirebilir.
Bu durumda da yakınlık analizi, kök türü, hatta kısmi bir anlamsal analiz çok daha iyi tavsiyelerde
bulunulmasını sağlayabilir.
Örneğin "Elmazlarının" kelimesi için "Elmalarının" ,"Elmaslarının", "Olmazlarının" tavsiyelerini 
verebilmek oldukça zorlu bir işmiş gibi görünüyor.


